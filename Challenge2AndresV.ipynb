{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de paqueterias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "import spacy\n",
    "#nltk.download('wordnet')\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_glass_completo=pd.read_csv(\"glassdoor_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hace un DF mas pequeño para trabajar mas facilemte\n",
    "#df_glass_mil =df_glass_completo.head(1000)\n",
    "\n",
    "#df_glass_mil.to_csv('glassdor_mil.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea df con prueba y test\n",
    "#train_set = df_glass_mil.sample(frac=0.8, random_state=42) \n",
    "#train_set.to_csv('glassdor_train.csv', index=False)\n",
    "\n",
    "# Drop de los datos que estan en el set train\n",
    " \n",
    "#test_set = df_glass_mil.drop(train_set.index) \n",
    "#test_set.to_csv('glassdor_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se trabaja con el train df\n",
    "\n",
    "df_glass=pd.read_csv(\"glassdor_train.csv\")\n",
    "df_glass.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN with , Na values interfere in the merge and re code\n",
    "\n",
    "df_glass['headline'] = df_glass['headline'].fillna(\",\")\n",
    "df_glass['pros'] = df_glass['pros'].fillna(\",\")\n",
    "df_glass['cons'] = df_glass['cons'].fillna(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge hedline, pros, cons\n",
    "\n",
    "df_glass[\"headline+pros+cons\"] = df_glass[\"headline\"] + \" \" + df_glass[\"pros\"]+ \" \" + df_glass[\"cons\"]\n",
    "\n",
    "df_glass[\"headline+pros+cons\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there is an Na in \"headline+pros+cons\"\n",
    "\n",
    "df_glass[df_glass[\"headline+pros+cons\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the info at column \"headline+pros+cons\" string\n",
    "\n",
    "df_glass['headline+pros+cons']= df_glass['headline+pros+cons'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Punctuation Marks\n",
    "\n",
    "def quitar_puntuacion(texto):\n",
    "    return re.sub(r'[^\\w\\s]',\"\", texto)\n",
    "\n",
    "# Apply function to the merged column\n",
    "\n",
    "df_glass['headline+pros+cons'] = df_glass['headline+pros+cons'].apply(quitar_puntuacion)\n",
    "\n",
    "#Remove Stop words\n",
    "def quitar_stop(texto):\n",
    "    return re.sub(r'\\b(?:and|an|at|a|of|on|I|for|with|the|at|from|in|to)\\b', \"\", texto, flags=re.IGNORECASE)\n",
    "\n",
    "# Apply function to the merged column\n",
    "\n",
    "df_glass['headline+pros+cons'] = df_glass['headline+pros+cons'].apply(quitar_stop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The info ended as type object, have to convert it to string\n",
    "df_glass['headline+pros+cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lematize\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lematizar_(text):\n",
    "    obj = nlp(text.lower())\n",
    "    lemmatize_token = [x.lemma_ for x in obj]\n",
    "    return lemmatize_token\n",
    "\n",
    "# Aplicamos la lematización a cada fila\n",
    "df_glass['headline+pros+cons_lemma'] = df_glass['headline+pros+cons'].apply(lematizar_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer lemma string\n",
    "df_glass['headline+pros+cons_lemma']=df_glass['headline+pros+cons_lemma'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Symbols Stop words\n",
    "def quitar_stop(texto):\n",
    "    return re.sub(r\"[ \\[\\],']\", \" \", texto, flags=re.IGNORECASE)\n",
    "\n",
    "# Apply function to the merged column\n",
    "\n",
    "df_glass['headline+pros+cons_cleanlemma'] = df_glass['headline+pros+cons_lemma'].apply(quitar_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DF with bigrams to record Y values (recommend)\n",
    "\n",
    "df_bigrams_recommend=pd.DataFrame({\"count\":[],\"Recommend\":[]})\n",
    "\n",
    "cc = 0\n",
    "\n",
    "for x in df_glass['headline+pros+cons_cleanlemma']:\n",
    "\n",
    "    text = df_glass['headline+pros+cons_cleanlemma'].iloc[cc]\n",
    "    #recommend = df_glass['recommend'].iloc[cc]\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    unigrams=list(ngrams(tokens, 1))\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "    Ngrams=-1 #To record all\n",
    "\n",
    "    #unigram_counts = (pd.Series(unigrams).value_counts())[:Ngrams]\n",
    "\n",
    "    bigram_counts = (pd.Series(bigrams).value_counts())[:Ngrams]\n",
    "    \n",
    "    #trigram_counts = (pd.Series(trigrams).value_counts())[:Ngrams]\n",
    "    \n",
    "\n",
    "    df_new = bigram_counts.to_frame()\n",
    "\n",
    "    df_new[\"Recommend\"]= df_glass['recommend'].iloc[cc]\n",
    "\n",
    "    df_bigrams_recommend = pd.concat([df_new, df_bigrams_recommend])\n",
    "    cc = cc+ 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index a columna\n",
    "df_bigrams_recommend=df_bigrams_recommend.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the DF with bigrams on a CSV\n",
    "df_bigrams_recommend.to_csv('Bigrams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se quitan los duplicados del reporte de recommend, y se remueve la columna count\n",
    "\n",
    "valores_bigrams_unicos = df_bigrams_recommend.drop_duplicates(subset=['index','Recommend'])\n",
    "valores_bigrams_unicos = valores_bigrams_unicos.drop('count',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_bigrams_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos los valores de la tupla a string, y depues concatenamos\n",
    "\n",
    "valores_bigrams_unicos[\"index\"]=valores_bigrams_unicos[\"index\"].astype(str)\n",
    "valores_bigrams_unicos[\"index+Recommend\"]=valores_bigrams_unicos[\"index\"]+ valores_bigrams_unicos[\"Recommend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_bigrams_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agarramos el df de las recomendaciones y hacemos el concatenado anterior\n",
    "\n",
    "df_bigrams_recommend_modificado=df_bigrams_recommend\n",
    "\n",
    "df_bigrams_recommend_modificado[\"index\"]=df_bigrams_recommend_modificado[\"index\"].astype(str)\n",
    "df_bigrams_recommend_modificado[\"index+Recommend\"]=df_bigrams_recommend_modificado[\"index\"]+ df_bigrams_recommend_modificado[\"Recommend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigrams_recommend_modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos un ciclo For para hacer la suma acumulada \"Frecuencia Bigrama + Reseña\"\n",
    "\n",
    "valores_bigrams_unicos[\"Frecuencia Bigrama + Reseña\"]=0\n",
    "loc=0\n",
    "\n",
    "for gramm in valores_bigrams_unicos['index+Recommend']:\n",
    "    cc=0\n",
    "    loc2=0\n",
    "    \n",
    "    for gramm_2 in df_bigrams_recommend_modificado ['index+Recommend']:\n",
    "        if gramm == gramm_2:\n",
    "            cc= cc+ df_bigrams_recommend_modificado['count'].iloc[loc2]\n",
    "        loc2=loc2+1\n",
    "    \n",
    "    valores_bigrams_unicos[\"Frecuencia Bigrama + Reseña\"].iloc[loc]=cc\n",
    "    loc=loc+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos un ciclo For para hacer la suma acumulada \"Frecuencia Bigrama\"\n",
    "\n",
    "valores_bigrams_unicos[\"Frecuencia Bigrama\"]=0\n",
    "loc=0\n",
    "\n",
    "for gramm in valores_bigrams_unicos['index']:\n",
    "    cc=0\n",
    "    loc2=0\n",
    "    \n",
    "    for gramm_2 in df_bigrams_recommend_modificado ['index']:\n",
    "        if gramm == gramm_2:\n",
    "            cc= cc+ df_bigrams_recommend_modificado['count'].iloc[loc2]\n",
    "        loc2=loc2+1\n",
    "    \n",
    "    valores_bigrams_unicos[\"Frecuencia Bigrama\"].iloc[loc]=cc\n",
    "    loc=loc+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos un ciclo For para calcular probabilidad\n",
    "\n",
    "valores_bigrams_unicos[\"Probabilidad\"]=0\n",
    "loc=0\n",
    "\n",
    "for fecuencia in valores_bigrams_unicos['index']:\n",
    "\n",
    "    valores_bigrams_unicos[\"Probabilidad\"].iloc[loc]=valores_bigrams_unicos[\"Frecuencia Bigrama + Reseña\"].iloc[loc]/valores_bigrams_unicos[\"Frecuencia Bigrama\"].iloc[loc]\n",
    "    loc=loc+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_bigrams_unicos\n",
    "\n",
    "valores_bigrams_unicos.to_csv('ProbabilidadBiGramm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer lo mismo de Bigrams a Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DF with unigrams to record Y values (recommend)\n",
    "\n",
    "df_uigrams_recommend=pd.DataFrame({\"count\":[],\"Recommend\":[]})\n",
    "\n",
    "cc = 0\n",
    "\n",
    "for x in df_glass['headline+pros+cons_cleanlemma']:\n",
    "\n",
    "    text = df_glass['headline+pros+cons_cleanlemma'].iloc[cc]\n",
    "    #recommend = df_glass['recommend'].iloc[cc]\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    unigrams=list(ngrams(tokens, 1))\n",
    "    #bigrams = list(ngrams(tokens, 2))\n",
    "    #trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "    Ngrams=-1 #To record all\n",
    "\n",
    "    unigram_counts = (pd.Series(unigrams).value_counts())[:Ngrams]\n",
    "\n",
    "    #bigram_counts = (pd.Series(bigrams).value_counts())[:Ngrams]\n",
    "    \n",
    "    #trigram_counts = (pd.Series(trigrams).value_counts())[:Ngrams]\n",
    "    \n",
    "\n",
    "    df_new = unigram_counts.to_frame()\n",
    "\n",
    "    df_new[\"Recommend\"]= df_glass['recommend'].iloc[cc]\n",
    "\n",
    "    df_uigrams_recommend = pd.concat([df_new, df_uigrams_recommend])\n",
    "    cc = cc+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uigrams_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index a columna\n",
    "df_uigrams_recommend = df_uigrams_recommend.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the DF with unigrams on a CSV\n",
    "df_uigrams_recommend.to_csv('Unigrams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se quitan los duplicados del reporte de recommend, y se remueve la columna count\n",
    "\n",
    "valores_unigrams_unicos = df_uigrams_recommend.drop_duplicates(subset=['index','Recommend'])\n",
    "valores_unigrams_unicos = valores_unigrams_unicos.drop('count',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unigrams_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos los valores de la tupla a string, y depues concatenamos\n",
    "\n",
    "valores_unigrams_unicos[\"index\"]=valores_unigrams_unicos[\"index\"].astype(str)\n",
    "valores_unigrams_unicos[\"index+Recommend\"]=valores_unigrams_unicos[\"index\"]+ valores_unigrams_unicos[\"Recommend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agarramos el df de las recomendaciones y hacemos el concatenado anterior\n",
    "\n",
    "df_uigrams_recommend_modificado=df_uigrams_recommend\n",
    "\n",
    "df_uigrams_recommend_modificado[\"index\"]=df_uigrams_recommend_modificado[\"index\"].astype(str)\n",
    "df_uigrams_recommend_modificado[\"index+Recommend\"]=df_uigrams_recommend_modificado[\"index\"]+ df_uigrams_recommend_modificado[\"Recommend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos un ciclo For para hacer la suma acumulada \"Frecuencia Unigrama + Reseña\"\n",
    "\n",
    "valores_unigrams_unicos[\"Frecuencia Unigrama + Reseña\"]=0\n",
    "loc=0\n",
    "\n",
    "for gramm in valores_unigrams_unicos['index+Recommend']:\n",
    "    cc=0\n",
    "    loc2=0\n",
    "    \n",
    "    for gramm_2 in df_uigrams_recommend_modificado ['index+Recommend']:\n",
    "        if gramm == gramm_2:\n",
    "            cc= cc+ df_uigrams_recommend_modificado['count'].iloc[loc2]\n",
    "        loc2=loc2+1\n",
    "    \n",
    "    valores_unigrams_unicos[\"Frecuencia Unigrama + Reseña\"].iloc[loc]=cc\n",
    "    loc=loc+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unigrams_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos un ciclo For para hacer la suma acumulada \"Frecuencia Bigrama\"\n",
    "\n",
    "valores_unigrams_unicos[\"Frecuencia Unigrama\"]=0\n",
    "loc=0\n",
    "\n",
    "for gramm in valores_unigrams_unicos['index']:\n",
    "    cc=0\n",
    "    loc2=0\n",
    "    \n",
    "    for gramm_2 in df_uigrams_recommend_modificado ['index']:\n",
    "        if gramm == gramm_2:\n",
    "            cc= cc+ df_uigrams_recommend_modificado['count'].iloc[loc2]\n",
    "        loc2=loc2+1\n",
    "    \n",
    "    valores_unigrams_unicos[\"Frecuencia Unigrama\"].iloc[loc]=cc\n",
    "    loc=loc+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos un ciclo For para calcular probabilidad\n",
    "\n",
    "valores_unigrams_unicos[\"Probabilidad\"]=0\n",
    "loc=0\n",
    "\n",
    "for fecuencia in valores_unigrams_unicos['index']:\n",
    "\n",
    "    valores_unigrams_unicos[\"Probabilidad\"].iloc[loc]=valores_unigrams_unicos[\"Frecuencia Unigrama + Reseña\"].iloc[loc]/valores_unigrams_unicos[\"Frecuencia Unigrama\"].iloc[loc]\n",
    "    loc=loc+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unigrams_unicos\n",
    "\n",
    "valores_unigrams_unicos.to_csv('ProbabilidadUniGramm.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unigrams_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer tabla prob limpia\n",
    "df_uigrams_test=pd.DataFrame({\"Word\":[],\"V\":[],\"X\":[],\"O\":[]})\n",
    "df_uigrams_test['Word']=valores_unigrams_unicos['index'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uigrams_test = df_uigrams_test.fillna(0)\n",
    "\n",
    "df_uigrams_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locw=0\n",
    "for word in df_uigrams_test['Word']:\n",
    "    loci=0\n",
    "    for index in valores_unigrams_unicos['index']:\n",
    "        if word == index:\n",
    "            if valores_unigrams_unicos['Recommend'].iloc[loci]=='v':\n",
    "                df_uigrams_test['V'].iloc[locw]=valores_unigrams_unicos['Probabilidad'].iloc[loci]\n",
    "            if valores_unigrams_unicos['Recommend'].iloc[loci]=='x':\n",
    "                df_uigrams_test['X'].iloc[locw]=valores_unigrams_unicos['Probabilidad'].iloc[loci]\n",
    "            if valores_unigrams_unicos['Recommend'].iloc[loci]=='o':\n",
    "                df_uigrams_test['O'].iloc[locw]=valores_unigrams_unicos['Probabilidad'].iloc[loci]\n",
    "        loci=loci+1\n",
    "    locw=locw+1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uigrams_test.to_csv('ProbabilidadUniGramm_VXO.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular probabilidades\n",
    "\n",
    "df_puni=pd.read_csv(\"glassdor_train.csv\")\n",
    "\n",
    "vv=0\n",
    "xx=0\n",
    "oo=0\n",
    "\n",
    "for reco in df_puni[\"recommend\"]:\n",
    "    if reco == \"v\":\n",
    "        vv=vv+1\n",
    "    if reco == \"x\":\n",
    "        xx=xx+1   \n",
    "    if reco == \"o\":\n",
    "        oo=oo+1\n",
    "\n",
    "tot_rec = vv+xx+oo\n",
    "prob_v= vv/tot_rec\n",
    "prob_x= xx/tot_rec\n",
    "prob_o= oo/tot_rec\n",
    "\n",
    "print(f'Probabilidad de ocurrencia V: {prob_v}')\n",
    "print(f'Probabilidad de ocurrencia X: {prob_x}')\n",
    "print(f'Probabilidad de ocurrencia O: {prob_o}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se abre el df test\n",
    "\n",
    "df_glass_t_test=pd.read_csv(\"glassdor_test.csv\")\n",
    "df_glass_t_test.head(5)\n",
    "\n",
    "#-------Se le da formato--------------\n",
    "\n",
    "\n",
    "df_glass_t_test['headline'] = df_glass_t_test['headline'].fillna(\",\")\n",
    "df_glass_t_test['pros'] = df_glass_t_test['pros'].fillna(\",\")\n",
    "df_glass_t_test['cons'] = df_glass_t_test['cons'].fillna(\",\")\n",
    "\n",
    "#Merge hedline, pros, cons\n",
    "df_glass_t_test[\"headline+pros+cons\"] = df_glass_t_test[\"headline\"] + \" \" + df_glass_t_test[\"pros\"]+ \" \" + df_glass_t_test[\"cons\"]\n",
    "df_glass_t_test[\"headline+pros+cons\"]\n",
    "\n",
    "#Make the info at column \"headline+pros+cons\" string\n",
    "df_glass_t_test['headline+pros+cons']= df_glass_t_test['headline+pros+cons'].astype('string')\n",
    "\n",
    "#Remove Punctuation Marks\n",
    "# Apply function to the merged column\n",
    "df_glass_t_test['headline+pros+cons'] = df_glass_t_test['headline+pros+cons'].apply(quitar_puntuacion)\n",
    "\n",
    "#Remove Stop words\n",
    "# Apply function to the merged column\n",
    "df_glass_t_test['headline+pros+cons'] = df_glass_t_test['headline+pros+cons'].apply(quitar_stop)\n",
    "\n",
    "#Lematize\n",
    "# Aplicamos la lematización a cada fila\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df_glass_t_test['headline+pros+cons_lemma'] = df_glass_t_test['headline+pros+cons'].apply(lematizar_)\n",
    "\n",
    "#Hacer lemma string\n",
    "df_glass_t_test['headline+pros+cons_lemma']=df_glass_t_test['headline+pros+cons_lemma'].astype('string')\n",
    "\n",
    "#Remove Symbols Stop words\n",
    "# Apply function to the merged column\n",
    "df_glass_t_test['headline+pros+cons_cleanlemma'] = df_glass_t_test['headline+pros+cons_lemma'].apply(quitar_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea una columna para ubicar a usuario\n",
    "df_glass_t_test.index.name = 'User'\n",
    "#Index a columna\n",
    "df_glass_t_test = df_glass_t_test.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glass_t_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DF with unigrams to record Y values (recommend)\n",
    "\n",
    "df_uigrams_test=pd.DataFrame({\"count\":[],\"Recommend\":[],\"User\":[]})\n",
    "\n",
    "cc = 0\n",
    "\n",
    "for x in df_glass_t_test['headline+pros+cons_cleanlemma']:\n",
    "\n",
    "    text = df_glass_t_test['headline+pros+cons_cleanlemma'].iloc[cc]\n",
    "        \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    unigrams=list(ngrams(tokens, 1))\n",
    "\n",
    "    Ngrams=-1 #To record all\n",
    "\n",
    "    unigram_counts = (pd.Series(unigrams).value_counts())[:Ngrams]\n",
    "    \n",
    "\n",
    "    df_new = unigram_counts.to_frame()\n",
    "\n",
    "    df_new[\"Recommend\"]= df_glass_t_test['recommend'].iloc[cc]\n",
    "    df_new[\"User\"]= df_glass_t_test['User'].iloc[cc]\n",
    "\n",
    "    df_uigrams_test = pd.concat([df_new, df_uigrams_test])\n",
    "    cc = cc+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index a columna\n",
    "df_uigrams_test = df_uigrams_test.reset_index()\n",
    "#Save the DF with unigrams test on a CSV\n",
    "df_uigrams_test.to_csv('Unigrams_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uigrams_test[\"index\"]=df_uigrams_test[\"index\"].astype(str)\n",
    "df_uigrams_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abre csv Probabilidades\n",
    "df_prob=pd.read_csv('ProbabilidadUniGramm_VXO.csv')\n",
    "df_prob.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular Probabilidades Unigram\n",
    "\n",
    "#Primero sacamos los usuarios unicos\n",
    "\n",
    "usuarios_unicos=pd.DataFrame({\"User\":[],\"ProbV\":[],\"ProbX\":[],\"ProbO\":[]})\n",
    "\n",
    "usuarios_unicos['User']=df_uigrams_test[\"User\"].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quita Na\n",
    "\n",
    "usuarios_unicos = usuarios_unicos.fillna(0)\n",
    "\n",
    "usuarios_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loccu=0\n",
    "for user in usuarios_unicos['User']:\n",
    "    locct=0\n",
    "    for palabra_test in df_uigrams_test[\"index\"]:\n",
    "        if user == df_uigrams_test[\"User\"].iloc[locct]:\n",
    "            loccp=0\n",
    "            for pal_prob in df_prob [\"Word\"]:\n",
    "                if pal_prob == palabra_test:\n",
    "                    if df_prob [\"V\"].iloc[loccp] != 0:\n",
    "                        if usuarios_unicos['ProbV'].iloc[loccu]==0:\n",
    "                            usuarios_unicos['ProbV'].iloc[loccu]=1\n",
    "                        usuarios_unicos['ProbV'].iloc[loccu]= usuarios_unicos['ProbV'].iloc[loccu]*(df_prob [\"V\"].iloc[loccp]**df_uigrams_test[\"count\"].iloc[locct])\n",
    "                    \n",
    "                    if df_prob [\"X\"].iloc[loccp] != 0:\n",
    "                        if usuarios_unicos['ProbX'].iloc[loccu]==0:\n",
    "                            usuarios_unicos['ProbX'].iloc[loccu]=1\n",
    "                        usuarios_unicos['ProbX'].iloc[loccu]= usuarios_unicos['ProbX'].iloc[loccu]*(df_prob [\"X\"].iloc[loccp]**df_uigrams_test[\"count\"].iloc[locct])\n",
    "                    \n",
    "                    if df_prob [\"O\"].iloc[loccp] != 0:\n",
    "                        if usuarios_unicos['ProbO'].iloc[loccu]==0:\n",
    "                            usuarios_unicos['ProbO'].iloc[loccu]=1\n",
    "                        usuarios_unicos['ProbO'].iloc[loccu]= usuarios_unicos['ProbO'].iloc[loccu]*(df_prob [\"O\"].iloc[loccp]**df_uigrams_test[\"count\"].iloc[locct])\n",
    "                loccp=loccp+1\n",
    "        locct=locct+1\n",
    "    loccu=loccu+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cálculo de numeradores por Usuario:\")\n",
    "usuarios_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizacion para encontrar las probabilidades reales\n",
    "\n",
    "#Se saca el total de las probabilidades por usuario\n",
    "\n",
    "usuarios_unicos[\"SumProb\"]=0\n",
    "\n",
    "locs=0\n",
    "\n",
    "for usuario in usuarios_unicos[\"SumProb\"]:\n",
    "    usuarios_unicos[\"SumProb\"].iloc[locs]=usuarios_unicos[\"ProbV\"].iloc[locs]+usuarios_unicos[\"ProbX\"].iloc[locs]+usuarios_unicos[\"ProbO\"].iloc[locs]\n",
    "    locs=locs+1\n",
    "#Cálculo probabilidad normalizada\n",
    "usuarios_unicos[\"ProbNomV%\"]=0\n",
    "usuarios_unicos[\"ProbNomX%\"]=0\n",
    "usuarios_unicos[\"ProbNomO%\"]=0\n",
    "\n",
    "locn=0\n",
    "\n",
    "for usuario in usuarios_unicos[\"ProbNomV%\"]:\n",
    "    usuarios_unicos[\"ProbNomV%\"].iloc[locn]=round((usuarios_unicos[\"ProbV\"].iloc[locn]/usuarios_unicos[\"SumProb\"].iloc[locn])*100,2)\n",
    "    usuarios_unicos[\"ProbNomX%\"].iloc[locn]=round((usuarios_unicos[\"ProbX\"].iloc[locn]/usuarios_unicos[\"SumProb\"].iloc[locn])*100,2)\n",
    "    usuarios_unicos[\"ProbNomO%\"].iloc[locn]=round((usuarios_unicos[\"ProbO\"].iloc[locn]/usuarios_unicos[\"SumProb\"].iloc[locn])*100,2)\n",
    "    locn=locn+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparar resultados obtenidos vs train\n",
    "\n",
    "usuarios_unicos['Answer Predicted']=\" \"\n",
    "locap=0\n",
    "for user in usuarios_unicos['User']:\n",
    "    xVal=usuarios_unicos['ProbNomX%'].iloc[locap]\n",
    "    vVal=usuarios_unicos['ProbNomV%'].iloc[locap]\n",
    "    oVal=usuarios_unicos['ProbNomO%'].iloc[locap]\n",
    "    if xVal > vVal and xVal > oVal:\n",
    "        usuarios_unicos['Answer Predicted'].iloc[locap]='x'\n",
    "    if vVal > xVal and vVal > oVal:\n",
    "        usuarios_unicos['Answer Predicted'].iloc[locap]='v'\n",
    "    if oVal > vVal and oVal > xVal:\n",
    "        usuarios_unicos['Answer Predicted'].iloc[locap]='o'\n",
    "    locap=locap+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_unicos.to_csv('Results_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uigrams_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_unicos['Real Answer']=\" \"\n",
    "locus=0\n",
    "for user in usuarios_unicos[\"User\"]:\n",
    "    locni=0\n",
    "    for useruni in df_uigrams_test[\"User\"]:\n",
    "        if user == useruni:\n",
    "            usuarios_unicos[\"Real Answer\"].iloc[locus]=df_uigrams_test[\"Recommend\"].iloc[locni]\n",
    "        locni=locni+1\n",
    "    locus=locus+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=usuarios_unicos[\"Answer Predicted\"]\n",
    "y_test=usuarios_unicos[\"Real Answer\"]\n",
    "\n",
    "tP=0\n",
    "sUM=0\n",
    "cc=0\n",
    "\n",
    "for x in y_pred:\n",
    "    sUM=sUM+1\n",
    "    if x == y_test.iloc[cc]:\n",
    "        tP = tP + 1\n",
    "    cc=cc+1\n",
    "\n",
    "print(f'Accuracy: {tP/sUM}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Estadistica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
